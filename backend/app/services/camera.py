import cv2
import threading
import queue
import time
import torch
import asyncio
from ultralytics import YOLO

# Cache ƒë·ªÉ tr√°nh spam log human detection (gi·ªëng temp_alert_cache)
_human_detection_cache: dict[str, float] = {}  # deviceId -> last_detection_time
HUMAN_DETECTION_COOLDOWN = 30  # Ch·ªâ log 1 l·∫ßn m·ªói 30 gi√¢y


class CameraStream:
    def __init__(self, cameraUrl, deviceId, frameQueueSize=8, humanDetectionMode=False):
        """
        Kh·ªüi t·∫°o CameraStream.

        :param cameraUrl: URL c·ªßa camera stream (v√≠ d·ª•: http://192.168.1.100:80/stream)
        :param deviceId: ID c·ªßa device trong database
        :param frameQueueSize: K√≠ch th∆∞·ªõc t·ªëi ƒëa c·ªßa queue l∆∞u frame (m·∫∑c ƒë·ªãnh 4)
        :param humanDetectionMode: B·∫≠t/t·∫Øt ch·∫ø ƒë·ªô ph√°t hi·ªán ng∆∞·ªùi (m·∫∑c ƒë·ªãnh False)
        """
        self.cameraUrl = cameraUrl
        self.deviceId = deviceId
        self.frameQueue = queue.Queue(maxsize=frameQueueSize)
        self.humanDetectionMode = humanDetectionMode

        # Bi·∫øn thread
        self.captureThread = None
        self.detectionThread = None
        self.running = False

        self.processedFrame = None
        self.frameLock = threading.Lock()
        self.modeLock = threading.Lock()  # Mutex cho humanDetectionMode
        self.current_fps = 0.0
        self.fpsLock = threading.Lock()  # Mutex cho current_fps
        
        # Reference to event loop for async logging from thread
        self._loop = None
        
        # Kh·ªüi t·∫°o YOLO model v·ªõi GPU n·∫øu c√≥
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = YOLO('yolo11s.pt')
        self.model.to(self.device)
        print(f"üî• YOLO model loaded on: {self.device.upper()}")


    def start(self):
        """B·∫Øt ƒë·∫ßu c√°c lu·ªìng capture v√† detection."""
        if self.running:
            return
        self.running = True
        
        # L∆∞u event loop ƒë·ªÉ g·ªçi async t·ª´ thread
        try:
            self._loop = asyncio.get_event_loop()
        except:
            self._loop = None
            
        self.captureThread = threading.Thread(target=self._capture_frames, daemon=True)
        self.detectionThread = threading.Thread(target=self._detect_humans, daemon=True)
        self.captureThread.start()
        self.detectionThread.start()
        print("CameraStream started")

    def stop(self):
        """D·ª´ng c√°c lu·ªìng capture v√† detection."""
        if not self.running:
            return
        print(f"üõë Stopping CameraStream for {self.cameraUrl}")
        self.running = False
        
        # ƒê·ª£i threads k·∫øt th√∫c
        if self.captureThread and self.captureThread.is_alive():
            self.captureThread.join(timeout=3)
        if self.detectionThread and self.detectionThread.is_alive():
            self.detectionThread.join(timeout=3)
        
        print("‚úÖ CameraStream stopped successfully")

    def get_processed_frame(self):
        """L·∫•y frame ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω (processed frame) t·ª´ b√™n ngo√†i."""
        with self.frameLock:  # ƒê·ªìng b·ªô truy c·∫≠p
            return self.processedFrame.copy() if self.processedFrame is not None else None

    def set_detection_mode(self, enabled: bool):
        """C·∫≠p nh·∫≠t humanDetectionMode t·ª´ b√™n ngo√†i."""
        with self.modeLock:
            if self.humanDetectionMode != enabled:
                self.humanDetectionMode = enabled
                print(f"üîÑ Detection mode updated: {enabled}")

    def get_fps(self) -> float:
        """L·∫•y FPS hi·ªán t·∫°i."""
        with self.fpsLock:
            return self.current_fps

    def _capture_frames(self):
        """Lu·ªìng l·∫•y frame t·ª´ cameraUrl v√† put v√†o queue."""
        cap = cv2.VideoCapture(self.cameraUrl)
        if not cap.isOpened():
            print(f"‚ùå Cannot open camera stream: {self.cameraUrl}")
            self.running = False
            return

        print(f"‚úÖ Camera capture started: {self.cameraUrl}")
        
        while self.running:
            ret, frame = cap.read()
            if ret:
                # N·∫øu queue ƒë·∫ßy, b·ªè frame c≈© nh·∫•t v√† th√™m frame m·ªõi
                if self.frameQueue.full():
                    try:
                        self.frameQueue.get_nowait()  # B·ªè frame c≈©
                    except queue.Empty:
                        pass
                
                try:
                    self.frameQueue.put(frame, timeout=1)
                except queue.Full:
                    pass
            else:
                print("‚ö†Ô∏è Failed to capture frame")
                time.sleep(0.05)

        cap.release()
        print("üõë Camera capture thread stopped")

    def _detect_humans(self):
        """Lu·ªìng th·ª±c hi·ªán detection tr√™n frame t·ª´ queue."""
        with self.modeLock:
            initial_mode = self.humanDetectionMode
        print(f"‚úÖ Detection thread started (mode: {initial_mode})")
        
        frame_count = 0
        start_time = time.time()
        
        while self.running:
            try:
                frame = self.frameQueue.get(timeout=1)
                frame_count += 1
                processed_frame = frame.copy()

                # ƒê·ªçc humanDetectionMode v·ªõi mutex
                with self.modeLock:
                    detection_enabled = self.humanDetectionMode

                if detection_enabled and self.model:
                    results = self.model(processed_frame, classes=[0], device=self.device, verbose=False)
                    human_detected = False
                    for result in results:
                        for box in result.boxes:
                            if box.cls == 0:
                                human_detected = True
                                x1, y1, x2, y2 = map(int, box.xyxy[0])
                                cv2.rectangle(processed_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                                cv2.putText(processed_frame, "Person", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                    if human_detected:
                        print("üö® Human detected!")
                        # Log human detection v·ªõi cooldown ƒë·ªÉ tr√°nh spam
                        self._log_human_detection()
                else:
                    time.sleep(0.01)

                # T√≠nh FPS m·ªói 30 frames
                if frame_count % 30 == 0:
                    elapsed = time.time() - start_time
                    fps = 30 / elapsed if elapsed > 0 else 0
                    
                    # L∆∞u FPS v√†o bi·∫øn d√πng chung v·ªõi mutex
                    with self.fpsLock:
                        self.current_fps = fps
                    
                    detection_status = "ON" if detection_enabled else "OFF"
                    # print(f"üîç Detection FPS: {fps:.2f}, Mode: {detection_status}")
                    frame_count = 0
                    start_time = time.time()

                with self.frameLock:
                    self.processedFrame = processed_frame

            except queue.Empty:
                continue
        
        print("üõë Detection thread stopped")

    def _log_human_detection(self):
        """Log human detection v·ªõi cooldown ƒë·ªÉ tr√°nh spam"""
        global _human_detection_cache
        
        current_time = time.time()
        last_detection = _human_detection_cache.get(self.deviceId, 0)
        
        # Ch·ªâ log n·∫øu ƒë√£ qua cooldown period
        if current_time - last_detection < HUMAN_DETECTION_COOLDOWN:
            return
        
        _human_detection_cache[self.deviceId] = current_time
        
        # G·ªçi async log t·ª´ thread
        if self._loop:
            try:
                asyncio.run_coroutine_threadsafe(
                    self._async_log_human_detection(),
                    self._loop
                )
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to log human detection: {e}")

    async def _async_log_human_detection(self):
        """Async function ƒë·ªÉ ghi log v√†o database"""
        try:
            from beanie import PydanticObjectId
            from app.models.device import Device
            from app.models.room import Room
            from app.services.activity_log import ActivityLogService
            from app.models.activity_log import LogType
            
            device = await Device.get(PydanticObjectId(self.deviceId))
            if device and device.roomId:
                room = await Room.get(device.roomId)
                if room:
                    await ActivityLogService.create_log(
                        action="HUMAN_DETECTED",
                        message=f"üö® {device.name}: Human detected in room",
                        userId=None,
                        homeId=str(room.homeId),
                        log_type=LogType.WARNING
                    )
                    print(f"‚úÖ Human detection logged for {device.name}")
        except Exception as e:
            print(f"‚ö†Ô∏è Error logging human detection: {e}")